{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineer Challenge\n",
    "\n",
    "## Introducción\n",
    "En este notebook, se ofrece una solución al desafío de procesamiento de datos con Python. El propósito es examinar un conjunto de datos de tweets y abordar diversas preguntas mediante dos enfoques: uno enfocado en optimizar el tiempo de ejecución y otro en reducir el consumo de memoria.\n",
    "\n",
    "## Estructura del Proyecto\n",
    "La solución se organiza en diferentes funciones, cada una en su archivo correspondiente dentro de la carpeta `src`. A continuación, se presentan tres preguntas, cada una con dos enfoques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instalar paquetes necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: memory-profiler in c:\\users\\chris\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.61.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\chris\\appdata\\roaming\\python\\python312\\site-packages (from memory-profiler) (6.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install memory-profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuramos la ruta del archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\temp\\Challenge_DATA\\tweets.json\\farmers-protest-tweets-2021-2-4.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga de Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from datetime import datetime, date\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "from typing import List, Tuple\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from memory_profiler import memory_usage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos una función para analizar el performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_function(func, *args):\n",
    "    \"\"\"Mide el tiempo de ejecución y el uso de memoria de una función.\"\"\"\n",
    "    start_time = time.time()\n",
    "    result = func(*args)\n",
    "    end_time = time.time()\n",
    "\n",
    "    mem_usage = memory_usage((func, args), max_usage=True)\n",
    "\n",
    "    return result, end_time - start_time, mem_usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funciones\n",
    "1. Las top 10 fechas donde hay más tweets. Mencionar el usuario (username) que más publicaciones tiene por cada uno de esos días.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Código que no considera optimizar recursos de procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q1_deficiente(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "    \"\"\"\n",
    "    Devuelve las 10 fechas con más tweets y el usuario que más tweets publicó en esas fechas.\n",
    "\n",
    "    Parámetros:\n",
    "    - file_path: Ruta del archivo JSON que contiene los tweets.\n",
    "\n",
    "    Retorno:\n",
    "    - Lista de tuplas donde cada tupla contiene una fecha y el nombre del usuario que más tweets publicó\n",
    "      en esa fecha.\n",
    "    \"\"\"\n",
    "\n",
    "    # Cargar todos los tweets en memoria\n",
    "    tweets = []\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as json_file:\n",
    "        for line in json_file:\n",
    "            tweet = json.loads(line)\n",
    "            tweets.append(tweet)\n",
    "\n",
    "    # Inicializa contadores de tweets por fecha y usuario\n",
    "    date_tweet_count = defaultdict(int)\n",
    "    date_user_tweets = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    # Procesar los tweets\n",
    "    for tweet in tweets:\n",
    "        date_str = tweet[\"date\"][:10]  # Extrae la parte de la fecha\n",
    "        username = tweet[\"user\"][\"username\"]  # Obtiene el nombre de usuario\n",
    "\n",
    "        # Incrementar el contador para la fecha y el usuario\n",
    "        date_tweet_count[date_str] += 1\n",
    "        date_user_tweets[date_str][username] += 1\n",
    "\n",
    "    # Lista para almacenar la fecha y el usuario con más tweets\n",
    "    top_dates_users = []\n",
    "\n",
    "    for date, user_tweets in date_user_tweets.items():\n",
    "        max_user = max(user_tweets.items(), key=lambda x: x[1])  # Usuario más activo\n",
    "\n",
    "        # Agregar el resultado a la lista sin la cantidad total de tweets\n",
    "        top_dates_users.append((datetime.strptime(date, '%Y-%m-%d').date(), max_user[0], date_tweet_count[date]))\n",
    "\n",
    "    # Ordenar las fechas de forma descendente por la cantidad total de tweets\n",
    "    sorted_dates = sorted(top_dates_users, key=lambda x: x[2], reverse=True)\n",
    "\n",
    "    # Retornar solo las 10 fechas con más tweets (sin la cantidad total)\n",
    "    return [(date, user) for date, user, _ in sorted_dates[:10]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfoque de Memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q1_memory(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "    \"\"\"\n",
    "    Devuelve las 10 fechas con más tweets y el usuario que más tweets publicó en esas fechas.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Inicializa contadores de tweets por fecha y usuario\n",
    "    date_tweet_count = defaultdict(int)\n",
    "    date_user_tweets = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    # Procesar los tweets directamente del archivo\n",
    "    with open(file_path, 'r', encoding='utf-8') as json_file:\n",
    "        for line in json_file:\n",
    "            tweet = json.loads(line)\n",
    "            date_str = tweet[\"date\"][:10]  # Extrae la parte de la fecha\n",
    "            username = tweet[\"user\"][\"username\"]  # Obtiene el nombre de usuario\n",
    "\n",
    "            # Incrementar el contador para la fecha y el usuario\n",
    "            date_tweet_count[date_str] += 1\n",
    "            date_user_tweets[date_str][username] += 1\n",
    "\n",
    "    # Lista para almacenar la fecha y el usuario con más tweets\n",
    "    top_dates_users = []\n",
    "\n",
    "    for date_str, user_tweets in date_user_tweets.items():\n",
    "        # Almacena la fecha como un objeto date directamente\n",
    "        current_date = datetime.strptime(date_str, '%Y-%m-%d').date()\n",
    "        max_user = max(user_tweets.items(), key=lambda x: x[1])  # Usuario más activo\n",
    "\n",
    "        # Agregar el resultado a la lista sin la cantidad total de tweets\n",
    "        top_dates_users.append((current_date, max_user[0]))\n",
    "\n",
    "    # Ordenar las fechas de forma descendente por la cantidad total de tweets\n",
    "    sorted_dates = sorted(top_dates_users, key=lambda x: date_tweet_count[x[0].isoformat()], reverse=True)\n",
    "\n",
    "    # Retornar solo las 10 fechas con más tweets (sin la cantidad total)\n",
    "    return sorted_dates[:10]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfoque de Tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q1_time(file_path: str) -> List[Tuple[date, str]]:\n",
    "    \"\"\"\n",
    "    Devuelve las 10 fechas con más tweets y el usuario que más tweets publicó en esas fechas.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Inicializa contadores de tweets por fecha y usuario\n",
    "    date_tweet_count = defaultdict(int)\n",
    "    date_user_tweets = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    # Procesar los tweets directamente del archivo\n",
    "    with open(file_path, 'r', encoding='utf-8') as json_file:\n",
    "        for line in json_file:\n",
    "            tweet = json.loads(line)\n",
    "            date_str = tweet[\"date\"][:10]  # Extrae la parte de la fecha\n",
    "            username = tweet[\"user\"][\"username\"]  # Obtiene el nombre de usuario\n",
    "\n",
    "            # Incrementar el contador para la fecha y el usuario\n",
    "            date_tweet_count[date_str] += 1\n",
    "            date_user_tweets[date_str][username] += 1\n",
    "\n",
    "    # Lista para almacenar la fecha y el usuario con más tweets\n",
    "    top_dates_users = []\n",
    "\n",
    "    for date_str, user_tweets in date_user_tweets.items():\n",
    "        # Almacena la fecha como un objeto date directamente\n",
    "        current_date = datetime.strptime(date_str, '%Y-%m-%d').date()\n",
    "        max_user, _ = max(user_tweets.items(), key=lambda x: x[1])  # Usuario más activo\n",
    "\n",
    "        # Agregar el resultado a la lista sin la cantidad total de tweets\n",
    "        top_dates_users.append((current_date, max_user))\n",
    "\n",
    "    # Ordenar las fechas de forma descendente por la cantidad total de tweets\n",
    "    sorted_dates = sorted(top_dates_users, key=lambda x: date_tweet_count[x[0].isoformat()], reverse=True)\n",
    "\n",
    "    # Retornar solo las 10 fechas con más tweets (sin la cantidad total)\n",
    "    return sorted_dates[:10]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de uso de memoria y tiempo de ejecución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultado Q1 (Tiempo): [(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria'), (datetime.date(2021, 2, 19), 'Preetm91')]\n",
      "Tiempo de ejecución (Tiempo): 3.82 segundos\n",
      "Uso máximo de memoria (Tiempo): 1373.01953125 MiB\n",
      "\n",
      "Resultado Q1 (Memoria): [(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria'), (datetime.date(2021, 2, 19), 'Preetm91')]\n",
      "Tiempo de ejecución (Memoria): 3.96 segundos\n",
      "Uso máximo de memoria (Memoria): 1373.01953125 MiB\n",
      "\n",
      "Resultado Q1 (Deficiente): [(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria'), (datetime.date(2021, 2, 19), 'Preetm91')]\n",
      "Tiempo de ejecución (Deficiente): 7.15 segundos\n",
      "Uso máximo de memoria (Deficiente): 2124.015625 MiB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Medición para la versión optimizada en tiempo\n",
    "result_q1_time, time_q1_time, mem_usage_time = measure_function(q1_time, file_path)\n",
    "print(f\"\\nResultado Q1 (Tiempo): {result_q1_time}\")\n",
    "print(f\"Tiempo de ejecución (Tiempo): {time_q1_time:.2f} segundos\")\n",
    "print(f\"Uso máximo de memoria (Tiempo): {mem_usage_time} MiB\")\n",
    "\n",
    "# Medición para la versión optimizada en memoria\n",
    "result_q1_memory, time_q1_memory, mem_usage_memory = measure_function(q1_memory, file_path)\n",
    "print(f\"\\nResultado Q1 (Memoria): {result_q1_memory}\")\n",
    "print(f\"Tiempo de ejecución (Memoria): {time_q1_memory:.2f} segundos\")\n",
    "print(f\"Uso máximo de memoria (Memoria): {mem_usage_memory} MiB\")\n",
    "\n",
    "# Medición para el código deficiente\n",
    "result_q1_deficiente, time_q1_deficiente, mem_usage_deficiente = measure_function(q1_deficiente, file_path)\n",
    "print(f\"\\nResultado Q1 (Deficiente): {result_q1_deficiente}\")\n",
    "print(f\"Tiempo de ejecución (Deficiente): {time_q1_deficiente:.2f} segundos\")\n",
    "print(f\"Uso máximo de memoria (Deficiente): {mem_usage_deficiente} MiB\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. El top 10 histórico de usuarios (username) más influyentes en función del conteo de las menciones (@) que registra cada uno de ellos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Código que no considera optimizar recursos de procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q2_deficiente(file_path: str) -> List[Tuple[str, int]]:\n",
    "    \"\"\"\n",
    "    Devuelve los 10 emojis más usados en el archivo JSON de tweets.\n",
    "    Este método está optimizado para el uso de memoria al procesar el archivo línea por línea.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Patrón regex para encontrar emojis en el texto.\n",
    "    emoji_pattern = re.compile(\n",
    "        r'[\\U0001F600-\\U0001F64F]|[\\U0001F300-\\U0001F5FF]|[\\U0001F680-\\U0001F6FF]|[\\U0001F700-\\U0001F77F]|[\\U0001F900-\\U0001F9FF]|[\\u2600-\\u2B55]'\n",
    "    )\n",
    "\n",
    "    # Carga todos los tweets en memoria (ineficiente)\n",
    "    tweet_list = open(file_path, 'r', encoding='utf-8').readlines()\n",
    "    \n",
    "    # Inicializa un contador para los emojis.\n",
    "    emoji_counter = Counter()\n",
    "\n",
    "    # Procesa cada línea (tweet) del archivo.\n",
    "    for line in tweet_list:\n",
    "        try:\n",
    "            # Convierte la línea JSON a un diccionario.\n",
    "            tweet = json.loads(line)\n",
    "            \n",
    "            # Verifica que el tweet contenga la clave 'content'.\n",
    "            if 'content' in tweet:\n",
    "                # Busca todos los emojis en el contenido del tweet.\n",
    "                emojis = emoji_pattern.findall(tweet[\"content\"])\n",
    "                \n",
    "                # Incrementa el contador para cada emoji encontrado.\n",
    "                for emoji in emojis:\n",
    "                    emoji_counter[emoji] += 1\n",
    "                    \n",
    "        except (json.JSONDecodeError, KeyError):\n",
    "            # Ignora líneas que no se pueden decodificar como JSON o que no tienen la clave 'content'.\n",
    "            continue\n",
    "\n",
    "    # Obtiene los 10 emojis más comunes y sus conteos.\n",
    "    top_emojis = emoji_counter.most_common(10)\n",
    "\n",
    "    # Retorna la lista de los 10 emojis más utilizados.\n",
    "    return top_emojis\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfoque de Memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q2_memory(file_path: str) -> List[Tuple[str, int]]:\n",
    "    \"\"\"\n",
    "    Devuelve los 10 emojis más usados en el archivo JSON de tweets.\n",
    "    Este método está optimizado para el uso de memoria al procesar el archivo línea por línea.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Patrón regex para encontrar emojis en el texto.\n",
    "    emoji_pattern = re.compile(\n",
    "        r'[\\U0001F600-\\U0001F64F]|[\\U0001F300-\\U0001F5FF]|[\\U0001F680-\\U0001F6FF]|[\\U0001F700-\\U0001F77F]|[\\U0001F900-\\U0001F9FF]|[\\u2600-\\u2B55]'\n",
    "    )\n",
    "\n",
    "    # Inicializa un contador para los emojis.\n",
    "    emoji_counter = Counter()\n",
    "    \n",
    "    try:\n",
    "        # Abre el archivo JSON para leer línea por línea.\n",
    "        with open(file_path, 'r', encoding='utf-8') as json_file:\n",
    "            # Procesa cada línea (tweet) del archivo.\n",
    "            for line in json_file:\n",
    "                try:\n",
    "                    # Convierte la línea JSON a un diccionario.\n",
    "                    tweet = json.loads(line)\n",
    "                    \n",
    "                    # Verifica que el tweet contenga la clave 'content'.\n",
    "                    if 'content' in tweet:\n",
    "                        # Busca todos los emojis en el contenido del tweet.\n",
    "                        emojis = emoji_pattern.findall(tweet[\"content\"])\n",
    "                        \n",
    "                        # Actualiza el contador con los emojis encontrados.\n",
    "                        emoji_counter.update(emojis)\n",
    "\n",
    "                except (json.JSONDecodeError, KeyError):\n",
    "                    # Ignora líneas que no se pueden decodificar como JSON o que no tienen la clave 'content'.\n",
    "                    continue\n",
    "\n",
    "        # Obtiene los 10 emojis más comunes y sus conteos.\n",
    "        top_emojis = emoji_counter.most_common(10)\n",
    "        \n",
    "        # Retorna la lista de los 10 emojis más utilizados.\n",
    "        return top_emojis\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        # Maneja el caso en que el archivo no se encuentra.\n",
    "        print(f\"Error: El archivo '{file_path}' no se encuentra.\")\n",
    "        return []\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfoque de Tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q2_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "    \"\"\"\n",
    "    Devuelve los 10 emojis más usados en el archivo JSON de tweets.\n",
    "    Este método está optimizado para el tiempo de ejecución al procesar el archivo de manera eficiente.\n",
    "      \n",
    "    \"\"\"\n",
    "\n",
    "    # Patrón regex para encontrar emojis en el texto.\n",
    "    emoji_pattern = re.compile(\n",
    "        r'[\\U0001F600-\\U0001F64F]|[\\U0001F300-\\U0001F5FF]|[\\U0001F680-\\U0001F6FF]|[\\U0001F700-\\U0001F77F]|[\\U0001F900-\\U0001F9FF]|[\\u2600-\\u2B55]'\n",
    "    )\n",
    "\n",
    "    # Inicializa un contador para los emojis.\n",
    "    emoji_counter = Counter()\n",
    "    \n",
    "    try:\n",
    "        # Abre el archivo JSON para leer línea por línea.\n",
    "        with open(file_path, 'r', encoding='utf-8') as json_file:\n",
    "            # Procesa cada línea (tweet) del archivo.\n",
    "            for line in json_file:\n",
    "                try:\n",
    "                    # Convierte la línea JSON a un diccionario.\n",
    "                    tweet = json.loads(line)\n",
    "                    \n",
    "                    # Verifica que el tweet contenga la clave 'content'.\n",
    "                    if 'content' in tweet:\n",
    "                        # Busca todos los emojis en el contenido del tweet.\n",
    "                        emojis = emoji_pattern.findall(tweet[\"content\"])\n",
    "                        \n",
    "                        # Actualiza el contador con los emojis encontrados.\n",
    "                        emoji_counter.update(emojis)\n",
    "\n",
    "                except (json.JSONDecodeError, KeyError):\n",
    "                    # Ignora líneas que no se pueden decodificar como JSON o que no tienen la clave 'content'.\n",
    "                    continue\n",
    "\n",
    "        # Obtiene los 10 emojis más comunes y sus conteos.\n",
    "        top_emojis = emoji_counter.most_common(10)\n",
    "        \n",
    "        # Retorna la lista de los 10 emojis más utilizados.\n",
    "        return top_emojis\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        # Maneja el caso en que el archivo no se encuentra.\n",
    "        print(f\"Error: El archivo '{file_path}' no se encuentra.\")\n",
    "        return []\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de uso de memoria y tiempo de ejecución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultado Q2 (Tiempo): [('🙏', 7286), ('😂', 3072), ('🚜', 2972), ('✊', 2411), ('🌾', 2363), ('🏻', 2080), ('❤', 1779), ('🤣', 1668), ('🏽', 1218), ('👇', 1108)]\n",
      "Tiempo de ejecución (Tiempo): 4.43 segundos\n",
      "Uso máximo de memoria (Tiempo): 1356.2578125 MiB\n",
      "\n",
      "Resultado Q2 (Memoria): [('🙏', 7286), ('😂', 3072), ('🚜', 2972), ('✊', 2411), ('🌾', 2363), ('🏻', 2080), ('❤', 1779), ('🤣', 1668), ('🏽', 1218), ('👇', 1108)]\n",
      "Tiempo de ejecución (Memoria): 4.37 segundos\n",
      "Uso máximo de memoria (Memoria): 1356.2578125 MiB\n",
      "\n",
      "Resultado Q2 (Deficiente): [('🙏', 7286), ('😂', 3072), ('🚜', 2972), ('✊', 2411), ('🌾', 2363), ('🏻', 2080), ('❤', 1779), ('🤣', 1668), ('🏽', 1218), ('👇', 1108)]\n",
      "Tiempo de ejecución (Deficiente): 4.57 segundos\n",
      "Uso máximo de memoria (Deficiente): 1638.50390625 MiB\n"
     ]
    }
   ],
   "source": [
    "# Medición para la versión optimizada en tiempo\n",
    "result_q2_time, time_q2_time, mem_usage_time = measure_function(q2_time, file_path)\n",
    "print(f\"\\nResultado Q2 (Tiempo): {result_q2_time}\")\n",
    "print(f\"Tiempo de ejecución (Tiempo): {time_q2_time:.2f} segundos\")\n",
    "print(f\"Uso máximo de memoria (Tiempo): {mem_usage_time} MiB\")\n",
    "\n",
    "# Medición para la versión optimizada en memoria\n",
    "result_q2_memory, time_q2_memory, mem_usage_memory = measure_function(q2_memory, file_path)\n",
    "print(f\"\\nResultado Q2 (Memoria): {result_q2_memory}\")\n",
    "print(f\"Tiempo de ejecución (Memoria): {time_q2_memory:.2f} segundos\")\n",
    "print(f\"Uso máximo de memoria (Memoria): {mem_usage_memory} MiB\")\n",
    "\n",
    "# Medición para el código deficiente\n",
    "result_q2_deficiente, time_q2_deficiente, mem_usage_deficiente = measure_function(q2_deficiente, file_path)\n",
    "print(f\"\\nResultado Q2 (Deficiente): {result_q2_deficiente}\")\n",
    "print(f\"Tiempo de ejecución (Deficiente): {time_q2_deficiente:.2f} segundos\")\n",
    "print(f\"Uso máximo de memoria (Deficiente): {mem_usage_deficiente} MiB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Análisis de sentimiento\n",
    "Enfoque de Memoria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Código que no considera optimizar recursos de procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from typing import List, Tuple\n",
    "\n",
    "def process_tweet(line: str, mention_counter: defaultdict) -> None:\n",
    "    \"\"\"\n",
    "    Procesa un tweet para extraer menciones de usuarios de manera ineficiente.\n",
    "\n",
    "    \"\"\"\n",
    "    # Cargar el tweet desde la línea JSON\n",
    "    tweet = json.loads(line)\n",
    "\n",
    "    # Obtener el nombre de usuario del autor\n",
    "    user = tweet.get(\"user\", {}).get(\"username\")\n",
    "    # Obtener el contenido del tweet\n",
    "    content = tweet.get(\"content\", \"\")\n",
    "\n",
    "    if user:\n",
    "        # Incrementar el contador para el autor del tweet\n",
    "        mention_counter[user] += 1\n",
    "        \n",
    "        # Extraer menciones de otros usuarios en el contenido del tweet\n",
    "        mentions = re.findall(r'@(\\w+)', content)\n",
    "\n",
    "        # Incrementar el contador de menciones por cada usuario mencionado\n",
    "        for mention in mentions:\n",
    "            # Incrementa el contador de menciones para cada mención\n",
    "            mention_counter[mention] += 1\n",
    "\n",
    "def q3_deficiente(file_path: str) -> List[Tuple[str, int]]:\n",
    "    \"\"\"\n",
    "    Analiza un archivo de tweets y cuenta las menciones de usuarios de manera ineficiente.\n",
    "    \n",
    "    Este método abre el archivo, procesa cada tweet y retorna las 10 menciones más comunes.\n",
    "    \"\"\"\n",
    "    # Inicializar un contador de menciones\n",
    "    mention_counter = defaultdict(int)\n",
    "\n",
    "    # Abrir el archivo JSON y procesar línea por línea\n",
    "    with open(file_path, 'r', encoding='utf-8') as json_file:\n",
    "        for line in json_file:\n",
    "            process_tweet(line, mention_counter)  # Procesar cada línea\n",
    "\n",
    "    # Ordenar los usuarios por el conteo de menciones de forma descendente\n",
    "    sorted_mentions = sorted(mention_counter.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Devolver las 10 menciones más comunes\n",
    "    return sorted_mentions[:10]\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfoque de Memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from collections import Counter\n",
    "from typing import List, Tuple\n",
    "\n",
    "def process_tweet_memory(line: str, mention_counter: Counter) -> None:\n",
    "    \"\"\"\n",
    "    Procesa un tweet para extraer menciones de usuarios.\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Cargar el tweet desde la línea JSON\n",
    "        tweet = json.loads(line)\n",
    "        # Obtener el nombre de usuario del autor\n",
    "        user = tweet.get(\"user\", {}).get(\"username\")\n",
    "        # Obtener el contenido del tweet\n",
    "        content = tweet.get(\"content\", \"\")\n",
    "\n",
    "        if user:\n",
    "            # Incrementar el contador para el autor del tweet\n",
    "            mention_counter[user] += 1\n",
    "            # Extraer menciones de otros usuarios en el contenido del tweet\n",
    "            mention_counter.update(re.findall(r'@(\\w+)', content))\n",
    "    except json.JSONDecodeError as e:\n",
    "        # Imprimir un mensaje de error si hay un problema con el formato JSON\n",
    "        print(f\"Error de JSON: {e}\")\n",
    "\n",
    "def q3_memory(file_path: str) -> List[Tuple[str, int]]:\n",
    "    \"\"\"\n",
    "    Analiza un archivo de tweets y cuenta las menciones de usuarios.\n",
    "\n",
    "    \"\"\"\n",
    "    mention_counter = Counter()  # Contador de menciones\n",
    "\n",
    "    try:\n",
    "        # Abrir el archivo JSON para leer línea por línea\n",
    "        with open(file_path, 'r', encoding='utf-8') as json_file:\n",
    "            for line in json_file:\n",
    "                # Procesar cada línea y actualizar el contador\n",
    "                process_tweet_memory(line, mention_counter)\n",
    "\n",
    "        # Devolver las 10 menciones más comunes\n",
    "        return mention_counter.most_common(10)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        # Imprimir un mensaje de error si el archivo no se encuentra\n",
    "        print(f\"Error: El archivo '{file_path}' no se encuentra.\")\n",
    "        return []\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfoque de Tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet_time(line: str) -> defaultdict:\n",
    "    \"\"\"\n",
    "    Procesa un tweet para extraer menciones de usuarios y devuelve un contador local.\n",
    "\n",
    "    \"\"\"\n",
    "    local_counter = defaultdict(int)  # Usar un diccionario simple\n",
    "    try:\n",
    "        tweet = json.loads(line)\n",
    "        user = tweet.get(\"user\", {}).get(\"username\")\n",
    "        content = tweet.get(\"content\", \"\")\n",
    "\n",
    "        if user:\n",
    "            local_counter[user] += 1  # Incrementa el conteo para el usuario\n",
    "\n",
    "            # Extrae menciones de otros usuarios en el contenido\n",
    "            mentions = re.findall(r'@(\\w+)', content)\n",
    "            for mention in mentions:\n",
    "                local_counter[mention] += 1  # Incrementa el conteo para cada mención\n",
    "    except json.JSONDecodeError:\n",
    "        pass  # Ignora líneas que no se pueden decodificar como JSON\n",
    "\n",
    "    return local_counter\n",
    "\n",
    "def q3_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "    \"\"\"\n",
    "    Analiza un archivo de tweets y cuenta las menciones de usuarios.\n",
    "\n",
    "    \"\"\"\n",
    "    total_counter = defaultdict(int)  # Contador global\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as json_file:\n",
    "            with ThreadPoolExecutor() as executor:\n",
    "                # Procesa cada línea del archivo de forma concurrente\n",
    "                results = executor.map(process_tweet_time, json_file)\n",
    "\n",
    "                # Suma los contadores locales al contador total\n",
    "                for local_counter in results:\n",
    "                    for user, count in local_counter.items():\n",
    "                        total_counter[user] += count\n",
    "\n",
    "        # Obtiene las 10 menciones más comunes\n",
    "        return sorted(total_counter.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: El archivo '{file_path}' no se encuentra.\")\n",
    "        return []\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de uso de memoria y tiempo de ejecución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultado Q3 (Tiempo): [('narendramodi', 2261), ('Kisanektamorcha', 1837), ('RakeshTikaitBKU', 1643), ('PMOIndia', 1422), ('RahulGandhi', 1125), ('GretaThunberg', 1046), ('RaviSinghKA', 1037), ('jot__b', 1035), ('rihanna', 972), ('UNHumanRights', 962)]\n",
      "Tiempo de ejecución (Tiempo): 10.83 segundos\n",
      "Uso máximo de memoria (Tiempo): 1339.41796875 MiB\n",
      "\n",
      "Resultado Q3 (Memoria): [('narendramodi', 2261), ('Kisanektamorcha', 1837), ('RakeshTikaitBKU', 1643), ('PMOIndia', 1422), ('RahulGandhi', 1125), ('GretaThunberg', 1046), ('RaviSinghKA', 1037), ('jot__b', 1035), ('rihanna', 972), ('UNHumanRights', 962)]\n",
      "Tiempo de ejecución (Memoria): 4.68 segundos\n",
      "Uso máximo de memoria (Memoria): 1299.19921875 MiB\n",
      "\n",
      "Resultado Q3 (Deficiente): [('narendramodi', 2261), ('Kisanektamorcha', 1837), ('RakeshTikaitBKU', 1643), ('PMOIndia', 1422), ('RahulGandhi', 1125), ('GretaThunberg', 1046), ('RaviSinghKA', 1037), ('jot__b', 1035), ('rihanna', 972), ('UNHumanRights', 962)]\n",
      "Tiempo de ejecución (Deficiente): 5.09 segundos\n",
      "Uso máximo de memoria (Deficiente): 1298.19921875 MiB\n"
     ]
    }
   ],
   "source": [
    "# Medición para la versión optimizada en tiempo\n",
    "result_q3_time, time_q3_time, mem_usage_time = measure_function(q3_time, file_path)\n",
    "print(f\"\\nResultado Q3 (Tiempo): {result_q3_time}\")\n",
    "print(f\"Tiempo de ejecución (Tiempo): {time_q3_time:.2f} segundos\")\n",
    "print(f\"Uso máximo de memoria (Tiempo): {mem_usage_time} MiB\")\n",
    "\n",
    "# Medición para la versión optimizada en memoria\n",
    "result_q3_memory, time_q3_memory, mem_usage_memory = measure_function(q3_memory, file_path)\n",
    "print(f\"\\nResultado Q3 (Memoria): {result_q3_memory}\")\n",
    "print(f\"Tiempo de ejecución (Memoria): {time_q3_memory:.2f} segundos\")\n",
    "print(f\"Uso máximo de memoria (Memoria): {mem_usage_memory} MiB\")\n",
    "\n",
    "# Medición para el código deficiente\n",
    "result_q3_deficiente, time_q3_deficiente, mem_usage_deficiente = measure_function(q3_deficiente, file_path)\n",
    "print(f\"\\nResultado Q3 (Deficiente): {result_q3_deficiente}\")\n",
    "print(f\"Tiempo de ejecución (Deficiente): {time_q3_deficiente:.2f} segundos\")\n",
    "print(f\"Uso máximo de memoria (Deficiente): {mem_usage_deficiente} MiB\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
